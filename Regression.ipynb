{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Q1. What is Simple Linear Regression?**"
      ],
      "metadata": {
        "id": "K0_7DFbokQ5X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans. Simple Linear Regression is a statistical method used to model the relationship between two continuous variables:\n",
        "\n",
        "* Independent variable (X): This is the predictor variable.\n",
        "* Dependent variable (Y): This is the variable we want to predict.\n",
        "\n"
      ],
      "metadata": {
        "id": "Gughw0W0kWRm"
      }
    },
    {
      "source": [
        "Y = β0 + β1*X + ε"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "0ouVFF7xlY9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Simple Linear Regression tries to find the best-fitting straight line through the data points. This line can then be used to predict the value of the dependent variable for a given value of the independent variable.\n",
        "\n",
        "Example.\n",
        "\n",
        "You could use Simple Linear Regression to predict a house's price (dependent variable) based on its size (independent variable). The regression model would find the line that best represents the relationship between house size and price. Then, you could use this line to predict the price of a house with a specific size."
      ],
      "metadata": {
        "id": "YvOohyyCldUI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2. What are the key assumptions of Simple Linear Regression?**"
      ],
      "metadata": {
        "id": "7Qjb-9krmQcM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans. Simple linear regression is a statistical method used to model the relationship between two variables: one independent variable (X) and one dependent variable (Y). It assumes a linear relationship between these variables, meaning the change in Y is proportional to the change in X.\n",
        "\n",
        "1. **Linearity** : The relationship between the independent variable (X) and the dependent variable (Y) must be linear.This means that the change in Y is proportional to the change in X, and can be represented by a straight line.\n",
        "\n",
        "2. **Independence of Errors**: The errors (residuals) in the model should be independent of each other. This means that the error associated with one observation should not be related to the error associated with another observation.\n",
        "\n",
        "3. **Homoscedasticity**: The variance of the errors (residuals) should be constant across all values of the independent variable(X). This means that the spread of the data points around the regression line should be consistent.\n",
        "\n",
        "4. **Normality of Errors**: The errors (residuals) should be normally distributed.This means that the distribution of the errors should follow a bell-shaped curve."
      ],
      "metadata": {
        "id": "OZvK-GGVm9KW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3. What does the coefficient m represent in the equation Y=mX+c?**"
      ],
      "metadata": {
        "id": "IB8DzG0arDc_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans.\n",
        "* Slope: The slope indicates how steep the line is and its direction.\n",
        "* Positive slope (m > 0): The line slants upwards from left to right.\n",
        "* Negative slope (m < 0): The line slants downwards from left to right.\n",
        "* Zero slope (m = 0): The line is horizontal.\n",
        "\n",
        "**key point.**\n",
        "\n",
        "* The slope is calculated as the ratio of the vertical change (rise) to the horizontal change (run) between any two points on the line.\n",
        "\n",
        "* The slope determines how much Y changes for a unit change in X.\n"
      ],
      "metadata": {
        "id": "ImyisT9ErMmG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q4. What does the intercept c represent in the equation Y=mX+c ?**"
      ],
      "metadata": {
        "id": "8kSgBk-Fvcly"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans. In the equation Y = mX + c, the coefficient 'c' represents the y-intercept of the line.\n",
        "\n",
        "* Y-intercept: This is the point where the line crosses the y-axis. In other words, it's the value of Y when X is equal to 0.\n",
        "\n",
        "* Key Points:\n",
        "\n",
        "* The y-intercept provides the starting point or baseline value of Y when the independent variable X is zero.\n",
        "\n",
        "* Its interpretation depends on the specific context of the problem.\n",
        "\n",
        "**In Summary:**\n",
        "\n",
        "* 'c' is an important parameter in the linear equation, indicating the value of Y at the beginning of the linear relationship (when X is zero).\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GnDvWmzZvlHl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q5. - How do we calculate the slope m in Simple Linear Regression?**"
      ],
      "metadata": {
        "id": "qhfzUPNU4cL2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans. In the equation of a simple linear regression line:\n",
        "\n",
        "Y = mX + c\n",
        "\n",
        "* m represents the slope of the line.\n",
        "* X is the independent variable.\n",
        "* Y is the dependent variable.\n",
        "* c is the y-intercept.\n",
        "\n",
        "**Formula for Calculating the Slope (m)**\n",
        "\n",
        "The slope (m) can be calculated using the following formula:\n",
        "\n",
        "**m = (nΣxy - ΣxΣy) / (nΣx² - (Σx)²)**\n",
        "\n",
        "**Where:**\n",
        "\n",
        "* n is the number of data points.  \n",
        "* Σx is the sum of all x-values.\n",
        "* Σy is the sum of all y-values.\n",
        "* Σxy is the sum of the product of each x-value and its corresponding y-value.\n",
        "* Σx² is the sum of the squares of all x-values\n",
        "\n",
        "**Interpretation of the Slope**\n",
        "\n",
        "* The slope (m) indicates the rate of change in the dependent variable (Y) for a unit change in the independent variable (X).\n",
        "\n",
        "* Positive slope: If 'm' is positive, it means that as X increases, Y also increases.\n",
        "\n",
        "* Negative slope: If 'm' is negative, it means that as X increases, Y decreases."
      ],
      "metadata": {
        "id": "KF1Ms0JN5IkL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q6.  What is the purpose of the least squares method in Simple Linear Regression?**"
      ],
      "metadata": {
        "id": "Z-pAiaxJ7DyP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans. The purpose of the least squares method in Simple Linear Regression is to find the line of best fit that minimizes the sum of the squared differences between the actual data points and the predicted values on the line.\n",
        "\n",
        "**In simpler terms:**\n",
        "\n",
        "* Imagine you have a scatter plot of data points.\n",
        "\n",
        "* The least squares method aims to find the straight line that comes closest to all the points on the plot.\n",
        "\n",
        "* It does this by minimizing the total squared distances between each data point and the corresponding point on the line.\n",
        "\n"
      ],
      "metadata": {
        "id": "32uNIxh67bI-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q7.  How is the coefficient of determination (R²) interpreted in Simple Linear Regression?**"
      ],
      "metadata": {
        "id": "UNlkbgypCzI4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans. In simple linear regression, the coefficient of determination (R²) represents the proportion of the variance in the dependent variable (Y) that is predictable from the independent variable(X).\n",
        "\n",
        "**Interpretation:**\n",
        "\n",
        "* R² ranges from 0 to 1.\n",
        "\n",
        "* R² = 0: The independent variable (X) does not explain any of the variance in the dependent variable (Y). The regression line is horizontal, and there's no linear relationship between X and Y.\n",
        "\n",
        "* R² = 1: The independent variable (X) perfectly explains all the variance in the dependent variable (Y). All data points fall perfectly on the regression line.\n",
        "\n",
        "* 0 < R² < 1: The independent variable (X) explains some, but not all, of the variance in the dependent variable (Y). The higher the R², the stronger the linear relationship between X and Y.\n",
        "\n",
        "Calculation:\n",
        "\n",
        "* R² = 1 - (Residual Sum of Squares / Total Sum of Squares)\n",
        "\n",
        "**Significance:**\n",
        "\n",
        "* R² helps assess the goodness-of-fit of the regression model.\n",
        "\n",
        "* A higher R² generally indicates a better fit, but it's important to consider other factors like the sample size, the presence of outliers, and the context of the analysis\n"
      ],
      "metadata": {
        "id": "1Q4bOnF0C8yT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q8. What is Multiple Linear Regression?**"
      ],
      "metadata": {
        "id": "9OeZW74b3dT3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans. Multiple Linear Regression is a statistical technique used to predict the value of a dependent variable based on the values of two or more independent variables.It's an extension of simple linear regression, which only considers one independent variable.\n",
        "\n",
        "**Key Concepts:**\n",
        "\n",
        "* Dependent Variable: The variable you're trying to predict (e.g., house price, sales revenue).\n",
        "\n",
        "* Independent Variables: The factors you believe influence the dependent variable (e.g., square footage, number of bedrooms, location).\n",
        "\n",
        "* Linear Relationship: The model assumes a linear relationship between the independent variables and the dependent variable"
      ],
      "metadata": {
        "id": "4MQwohQk3jSP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q9. What is the main difference between Simple and Multiple Linear Regression?**"
      ],
      "metadata": {
        "id": "btwBK08p5c6W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans. The key difference between Simple and Multiple Linear Regression lies in the number of independent variables used:  \n",
        "\n",
        "**Simple Linear Regression:**\n",
        "\n",
        "* Utilizes only one independent variable to predict the value of the dependent variable.\n",
        "* Focuses on the linear relationship between these two variables.\n",
        "\n",
        "**Multiple Linear Regression:**\n",
        "\n",
        "* Employs two or more independent variables to predict the value of the dependent variable.\n",
        "\n",
        "* Considers the combined influence of multiple factors on the outcome.\n",
        "\n",
        "In essence:\n",
        "\n",
        "* Simple Linear Regression is like trying to understand how much sunlight affects plant growth.\n",
        "* Multiple Linear Regression is like trying to understand how sunlight, water, soil quality, and temperature all together affect plant growth."
      ],
      "metadata": {
        "id": "-DtH6tbd5k4O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q10. What are the key assumptions of Multiple Linear Regression?**"
      ],
      "metadata": {
        "id": "Do9DKebF95mZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans.\n",
        "1. **Linearity:**\n",
        "\n",
        "* The relationship between the dependent variable and each independent variable is assumed to be linear.\n",
        "\n",
        "* This means the effect of each independent variable on the dependent variable is constant across all values of the independent variables.\n",
        "\n",
        "2. **No Multicollinearity:**\n",
        "\n",
        "* The independent variables should not be highly correlated with each other.\n",
        "\n",
        "* High correlation (multicollinearity) makes it difficult to isolate the individual effect of each independent variable on the dependent variable.\n",
        "\n",
        "3. **Homoscedasticity:**\n",
        "\n",
        "* The variance of the errors (residuals) is constant across all levels of the independent variables.\n",
        "\n",
        "* In simpler terms, the spread of the data points around the regression line should be roughly equal for all values of the independent variables.\n",
        "\n",
        "4. **Independence of Errors:**\n",
        "\n",
        "* The errors (residuals) are independent of each other.\n",
        "\n",
        "* This means that the error for one observation does not influence the error for another observation.\n",
        "\n",
        "5. **Normality of Errors:**\n",
        "\n",
        "* The errors (residuals) are normally distributed.\n",
        "\n",
        "* This assumption is important for hypothesis testing and confidence interval estimation.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "U9TvnRxl-BWv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q11.What is heteroscedasticity, and how does it affect the results of a Multiple Linear Regression model?**"
      ],
      "metadata": {
        "id": "jiWXorbuHjD5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans. In the context of multiple linear regression, heteroscedasticity refers to the situation where the variance of the error terms (residuals) is not constant across all levels of the independent variable(s).In simpler terms, the spread of the data points around the regression line is not uniform.\n",
        "\n",
        "**How Heteroscedasticity Affects Multiple Linear Regression Results**\n",
        "\n",
        "1. Inaccurate Standard Errors: The most significant consequence of heteroscedasticity is that it leads to inaccurate estimates of the standard errors of the regression coefficients. These standard errors are crucial for hypothesis testing and constructing confidence intervals.  \n",
        "\n",
        "* Underestimated Standard Errors: If the variance of the errors increases with the values of the independent variable, the standard errors will be underestimated. This can lead to inflated t-statistics, making it more likely to incorrectly reject the null hypothesis and conclude that a coefficient is statistically significant when it is not.\n",
        "\n",
        "* Overestimated Standard Errors: Conversely, if the variance of the errors decreases with the values of the independent variable, the standard errors will be overestimated. This can make it harder to detect true relationships between the variables, leading to an increased risk of Type II errors (failing to reject a false null hypothesis).\n",
        "\n",
        "2. Inefficient Estimates: Heteroscedasticity can also make the estimates of the regression coefficients less efficient. This means that the estimates may not be as precise as they could be if the errors were homoscedastic (constant variance).\n",
        "\n",
        "3. Invalid Hypothesis Tests: The F-test for overall significance of the regression model also relies on the assumption of homoscedasticity. If this assumption is violated, the F-test may not be valid, leading to unreliable conclusions about the model's overall fit."
      ],
      "metadata": {
        "id": "Q7dysJkmHu2A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q12. How can you improve a Multiple Linear Regression model with high multicollinearity ?**"
      ],
      "metadata": {
        "id": "TgPUv9udCMaz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans. Multicollinearity in multiple linear regression occurs when two or more predictor variables are highly correlated with each other.This can lead to unstable and unreliable coefficient estimates, making it difficult to interpret the individual effects of each predictor on the response variable.\n",
        "\n",
        "**Here are several strategies to address multicollinearity:**\n",
        "\n",
        "**1.Feature Selection:**\n",
        "\n",
        "* **Remove one of the correlated predictors:** If two or more predictors are highly correlated, you can remove one of them from the model. This is a simple approach, but it may lead to a loss of information if the removed predictor is important.\n",
        "\n",
        "* **Use feature selection techniques:** Techniques like stepwise regression, forward selection, or backward elimination can help identify and remove redundant predictors.\n",
        "\n",
        "**2.Combine Correlated Predictors:**\n",
        "\n",
        "* **Create a new predictor variable:** If two or more predictors are highly correlated, you can create a new predictor variable that is a linear combination of the original variables.For example, if you have two predictors, x1 and x2, you could create a new predictor x3 = x1 + x2.\n",
        "\n",
        " * **Use principal component analysis (PCA):** PCA can be used to transform the original predictors into a new set of uncorrelated components. These components can then be used as predictors in the regression model.\n",
        "\n",
        "**3. Regularization:**\n",
        "\n",
        "* **Ridge regression:** This technique adds a penalty to the sum of squared coefficients, which helps to shrink the coefficients of correlated predictors.\n",
        "\n",
        "* **Lasso regression:** This technique adds a penalty to the absolute value of the coefficients, which can cause some coefficients to be set to zero, effectively performing feature selection.\n",
        "\n",
        "**4. Increase Sample Size:**\n",
        "\n",
        "* With a larger sample size, the impact of multicollinearity on the coefficient estimates can be reduced. However, this may not always be feasible.\n",
        "\n",
        "**5. Centering the Predictors:**\n",
        "\n",
        "* Centering the predictors (subtracting the mean from each predictor) can sometimes help to reduce multicollinearity, especially when interaction terms are included in the model.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-23hzQzqCjBO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q13. What are some common techniques for transforming categorical variables for use in regression models?**"
      ],
      "metadata": {
        "id": "gnM3Z_qPHkiS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans.\n",
        "**1. One-Hot Encoding**\n",
        "\n",
        "* Concept: Creates a new binary column for each category within the categorical variable.\n",
        "\n",
        "* Example:\n",
        "\n",
        "* If the categorical variable \"Color\" has values \"Red\", \"Green\", and \"Blue\", one-hot encoding would create three new columns: \"Color_Red\", \"Color_Green\", and \"Color_Blue\".\n",
        "\n",
        "* A row with \"Red\" in the original column would have a 1 in \"Color_Red\" and 0 in the other two columns.\n",
        "\n",
        "**Pros:**\n",
        "\n",
        "* Simple to understand and implement.\n",
        "\n",
        "* Preserves all information from the categorical variable.\n",
        "\n",
        "**Cons:**\n",
        "\n",
        "* Can increase the number of features significantly, especially with many categories.\n",
        "\n",
        "* May lead to multicollinearity (perfect correlation between the newly created columns).\n",
        "\n",
        "**2. Label Encoding**\n",
        "\n",
        "* **Concept:** Assigns a unique integer to each category.\n",
        "\n",
        "* **Example:**\n",
        "\n",
        "* If the categorical variable \"Color\" has values \"Red\", \"Green\", and \"Blue\", label encoding might assign 1 to \"Red\", 2 to \"Green\", and 3 to \"Blue\".\n",
        "\n",
        "**Pros:**\n",
        "\n",
        "* Reduces the number of features compared to one-hot encoding.\n",
        "\n",
        "**Cons:**\n",
        "\n",
        "* Introduces an ordinal relationship between categories, which may not be appropriate if the categories are unordered.\n",
        "\n",
        "* The model might incorrectly interpret the encoded values as having a numerical order.\n",
        "\n",
        "**3. Ordinal Encoding**\n",
        "\n",
        "* **Concept:** Similar to label encoding, but used when the categories have a natural order (e.g., \"Low\", \"Medium\", \"High\").\n",
        "\n",
        "**Pros:**\n",
        "\n",
        "* Captures the ordinal relationship between categories.\n",
        "\n",
        "**Cons:**\n",
        "\n",
        "* Only applicable to ordinal categorical variables.\n",
        "\n",
        "* The model might assume equal distances between the encoded values.\n",
        "\n",
        "**4. Target Encoding**\n",
        "\n",
        "* Concept: Replaces each category with the mean (or other statistics) of the target variable for that category.\n",
        "\n",
        "**Pros:**\n",
        "\n",
        "* Can capture complex relationships between the categorical variable and the target variable.\n",
        "\n",
        "**Cons:**\n",
        "\n",
        "* Prone to overfitting, especially with small datasets.\n",
        "\n",
        "* Requires careful handling to avoid data leakage.\n"
      ],
      "metadata": {
        "id": "qtOFupcsHtQb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q14. What is the role of interaction terms in Multiple Linear Regression?**"
      ],
      "metadata": {
        "id": "3DGnWF0kR8jA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans. In Multiple Linear Regression, interaction terms play a crucial role in capturing complex relationships between variables.\n",
        "\n",
        "**What are Interaction Terms?**\n",
        "\n",
        "* Definition: An interaction term is a product of two or more independent variables in a regression model.\n",
        "\n",
        "* Purpose: They allow us to examine how the relationship between one independent variable and the dependent variable changes depending on the value of another independent variable.\n",
        "\n",
        "**Why are Interaction Terms Important?**\n",
        "\n",
        "**1. More Realistic Models:**\n",
        "\n",
        "* Real-world relationships are often not simple additive effects. Interaction terms account for these complexities, leading to more accurate and realistic models.\n",
        "\n",
        "**2. Improved Model Fit:**\n",
        "\n",
        "* Including relevant interaction terms can significantly improve the model's fit to the data, as measured by higher R-squared values and lower Mean Squared Error (MSE).\n",
        "\n",
        "**3. Deeper Insights:**\n",
        "\n",
        "* Interaction terms can reveal valuable insights into how variables work together to influence the outcome. This can lead to a better understanding of the underlying processes.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "C5sAIMYgSEur"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q13. What are some common techniques for transforming categorical variables for use in regression models?**"
      ],
      "metadata": {
        "id": "SUMV27lbzRSm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans.\n",
        "**1. One-Hot Encoding**\n",
        "\n",
        "* Concept: Creates a new binary column for each category within the categorical variable.\n",
        "\n",
        "* Example: If the categorical variable is \"Color\" with values \"Red,\" \"Green,\" and \"Blue,\" one-hot encoding would create three new columns: \"Color_Red,\" \"Color_Green,\" and \"Color_Blue.\" A row with \"Red\" would have a 1 in \"Color_Red\" and 0s in the other two columns.\n",
        "\n",
        "**2. Label Encoding**\n",
        "\n",
        "* Concept: Assigns a unique integer to each category.\n",
        "\n",
        "* Example: If the categorical variable is \"Color\" with values \"Red,\" \"Green,\" and \"Blue,\" label encoding might assign 1 to \"Red,\" 2 to \"Green,\" and 3 to \"Blue.\"\n",
        "\n",
        "**3.Ordinal Encoding**\n",
        "\n",
        "* **Concept:** Used when the categories have an inherent order (e.g., \"Low,\" \"Medium,\" \"High\"). Assigns increasing integers to categories based on their order.\n",
        "\n",
        "**4.Target Encoding**\n",
        "\n",
        "* Concept: Replaces each category with the mean (or other statistic) of the target variable for that category.\n",
        "\n",
        "* Example: If the target variable is \"Sales\" and the categorical variable is \"Region,\" target encoding for \"Region A\" would be the average sales in \"Region A.\"\n",
        "\n",
        "**5. Binary Encoding**\n",
        "\n",
        "* Concept: Converts categorical values into binary codes. More complex than one-hot encoding, often used for high-cardinality categorical variables.\n"
      ],
      "metadata": {
        "id": "Y1kvwJzwzkqc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q14. What is the role of interaction terms in Multiple Linear Regression.?**"
      ],
      "metadata": {
        "id": "Lv2Re8uk3gBZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans. In Multiple Linear Regression, interaction terms play a crucial role in capturing complex relationships between variables.\n",
        "\n",
        "**What are Interaction Terms?**\n",
        "\n",
        "* Definition: An interaction term is a product of two or more independent variables in a regression model.\n",
        "\n",
        "* Purpose: They allow us to examine how the relationship between one independent variable and the dependent variable changes depending on the value of another independent variable.\n",
        "\n",
        "**Why are Interaction Terms Important?**\n",
        "\n",
        "1. More Realistic Models:\n",
        "\n",
        "* Real-world relationships are often not simple additive effects. Interaction terms account for these complexities, leading to more accurate and realistic models.\n",
        "\n",
        "2. Improved Model Fit:\n",
        "\n",
        "* Including relevant interaction terms can significantly improve the model's fit to the data, as measured by higher R-squared values and lower Mean Squared Error (MSE).\n",
        "\n",
        "3. Deeper Insights:\n",
        "\n",
        "* Interaction terms can reveal valuable insights into how variables work together to influence the outcome. This can lead to a better understanding of the underlying processes."
      ],
      "metadata": {
        "id": "u5ARIeI83nLL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q15. How can the interpretation of intercept differ between Simple and Multiple Linear Regression?**"
      ],
      "metadata": {
        "id": "wfaBVSKI7BBV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans. **In Simple Linear Regression:**\n",
        "\n",
        "* Clear Interpretation: The intercept represents the predicted value of the dependent variable when the independent variable is zero. This is often a meaningful value within the context of the data.\n",
        "\n",
        "* Example: If you're modeling the relationship between hours studied and exam score, the intercept might represent the expected score of a student who studies zero hours.\n",
        "\n",
        "**In Multiple Linear Regression:**\n",
        "\n",
        "* Less Direct Interpretation: The intercept represents the predicted value of the dependent variable when all independent variables are zero. This might not always be a realistic or meaningful scenario.\n",
        "\n",
        "* Example: If you're modeling house prices based on factors like square footage, number of bedrooms, and location, the intercept would represent the predicted price of a house with zero square footage, zero bedrooms, and located at a specific \"zero\" location. This is often not a practical situation.\n",
        "\n",
        "**Key Differences:**\n",
        "\n",
        "* Number of Variables: In simple regression, the intercept is easier to interpret because it relates to a single independent variable being zero. In multiple regression, it involves multiple variables being zero simultaneously.\n",
        "\n",
        "* Real-World Applicability: The scenario of all independent variables being zero might be unrealistic or outside the range of the observed data in multiple regression."
      ],
      "metadata": {
        "id": "8UYRY63W7Itg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q16. What is the significance of the slope in regression analysis, and how does it affect predictions?**"
      ],
      "metadata": {
        "id": "b-uF7Hmi-t6-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans. The slope in regression analysis is a critical parameter that quantifies the relationship between the independent variable(s) and the dependent variable. It essentially tells us how much the dependent variable changes for a unit change in the independent variable(s).\n",
        "\n",
        "Key Aspects of the Slope:\n",
        "\n",
        "* Direction of the Relationship:\n",
        "\n",
        "* Positive Slope: Indicates a positive linear relationship. As the independent variable increases, the dependent variable also tends to increase.\n",
        "\n",
        "* Negative Slope: Suggests a negative linear relationship. As the independent variable increases, the dependent variable tends to decrease.\n",
        "\n",
        "* Zero Slope: Implies no linear relationship between the variables. Changes in the independent variable do not systematically affect the dependent variable.\n",
        "\n",
        "* Strength of the Relationship:\n",
        "\n",
        "* The magnitude (absolute value) of the slope provides an indication of the strength of the relationship. A larger slope magnitude generally suggests a stronger relationship, meaning that changes in the independent variable have a greater impact on the dependent variable.\n"
      ],
      "metadata": {
        "id": "SVLgS0cg-0BX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q17.  How does the intercept in a regression model provide context for the relationship between variables?**"
      ],
      "metadata": {
        "id": "8I_VwyiaiGjq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans. The intercept in a regression model provides valuable context for the relationship between variables by representing the predicted value of the dependent variable when all independent variables are equal to zero.\n",
        "\n",
        "* **Baseline Value:** The intercept establishes a baseline or starting point for the relationship. It indicates the expected value of the dependent variable in the absence of any influence from the independent variables.\n",
        "\n",
        "* **Meaningful Interpretation (Sometimes):**\n",
        "\n",
        "* **Simple Linear Regression:** In simpler models with a single independent variable, the intercept can have a clear and meaningful interpretation. For example, if modeling exam scores based on study hours, the intercept might represent the expected score of a student who studies zero hours.\n",
        "\n",
        "* **Multiple Linear Regression:** In more complex models with multiple predictors, interpreting the intercept directly might not always be meaningful or realistic. This is because the scenario of all independent variables being zero might not be a plausible or relevant situation within the context of the data."
      ],
      "metadata": {
        "id": "duqiHQd9iME_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q18. What are the limitations of using R² as a sole measure of model performance?**"
      ],
      "metadata": {
        "id": "_8SAZpUHlipd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans.R-squared (R²) is a commonly used metric in regression analysis to assess the goodness-of-fit of a model. It represents the proportion of variance in the dependent variable that is explained by the independent variables in the model.\n",
        "\n",
        "However, relying solely on R² as a measure of model performance can be misleading due to several limitations:\n",
        "\n",
        "1. Sensitivity to Sample Size and Number of Predictors:\n",
        "\n",
        "* R² tends to increase as the number of predictors in the model increases, even if these predictors are not truly related to the dependent variable. This can lead to overfitting, where the model performs well on the training data but poorly on new, unseen data.\n",
        "\n",
        "* In small sample sizes, R² can be artificially inflated, making the model appear to be a better fit than it actually is.\n",
        "\n",
        "2. Limited Interpretability in Non-linear Relationships:\n",
        "\n",
        "* R² is primarily designed for linear regression models. In cases where the relationship between the variables is non-linear, R² may not accurately reflect the true fit of the model.\n",
        "\n",
        "3. Insensitivity to Outliers:\n",
        "\n",
        "* Outliers can significantly impact R², potentially inflating it even if the model is not a good fit for the majority of the data.\n",
        "\n",
        "4. Doesn't Guarantee Predictive Accuracy:\n",
        "\n",
        "* A high R² value does not necessarily guarantee that the model will make accurate predictions on new, unseen data. Other factors, such as model complexity and the presence of outliers, can influence predictive accuracy.\n",
        "\n",
        "5. Doesn't Consider Model Assumptions:\n",
        "\n",
        "* R² does not directly assess whether the assumptions of the regression model (e.g., linearity, normality of residuals, homoscedasticity) are met. Violations of these assumptions can lead to misleading results, even with a high R²."
      ],
      "metadata": {
        "id": "as-m3-HhlpeO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q19.How would you interpret a large standard error for a regression coefficient?**"
      ],
      "metadata": {
        "id": "eH2cBEZ3onxr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans. A large standard error for a regression coefficient indicates that the estimate of that coefficient is less precise. This means that there's a higher degree of uncertainty surrounding the true value of the coefficient in the population.\n",
        "\n",
        "* Less Reliable Coefficient Estimate: A larger standard error suggests that the coefficient could have a wider range of possible true values. This makes it harder to draw definitive conclusions about the relationship between the independent variable and the dependent variable.\n",
        "\n",
        "* Wider Confidence Intervals: The confidence interval for the coefficient will be wider, meaning we are less certain about the true range of the coefficient's value.\n",
        "\n",
        "* Potential for Insignificant Results: If the standard error is very large, it might lead to a non-significant result (i.e., failing to reject the null hypothesis that the coefficient is zero), even if there is a true relationship between the variables.\n",
        "\n",
        "**Possible Causes of Large Standard Errors:**\n",
        "\n",
        "* Small Sample Size: With fewer data points, it's harder to get precise estimates of the coefficients.\n",
        "\n",
        "* High Variability in the Data: If there's a lot of noise or variability in the data, it becomes more difficult to discern the true relationship between the variables.\n",
        "\n",
        "* Multicollinearity: If independent variables are highly correlated with each other, it can inflate the standard errors of their coefficients.\n",
        "\n",
        "* Outliers: Outliers can significantly impact the regression model and increase the standard errors of the coefficients."
      ],
      "metadata": {
        "id": "OX0ndQl7owXk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q20. How can heteroscedasticity be identified in residual plots, and why is it important to address it?**\n"
      ],
      "metadata": {
        "id": "bh9Ch_ZY9iVq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans. Heteroscedasticity, or unequal variance of residuals, can be visually identified in residual plots by observing patterns such as:\n",
        "\n",
        "* **Cone or Fan Shape:** As the fitted values (predicted values) increase, the spread of the residuals also increases, creating a cone or fan-like shape.\n",
        "\n",
        "* **Increasing or Decreasing Spread:** The residuals exhibit a clear trend of increasing or decreasing variance as the fitted values change.\n",
        "\n",
        "\n",
        "* **Clusters of High or Low Variance:** There are distinct clusters of points with either high or low variance in the residuals.\n",
        "\n",
        "**Why Address Heteroscedasticity?**\n",
        "\n",
        "Addressing heteroscedasticity is crucial because it can:\n",
        "\n",
        "* Invalidate Statistical Inference: Standard errors of the regression coefficients are often underestimated in the presence of heteroscedasticity. This can lead to incorrect conclusions about the statistical significance of the coefficients.\n",
        "\n",
        "* Reduce Model Efficiency: Heteroscedasticity can reduce the efficiency of the regression model, making it less accurate in predicting new data points.\n",
        "\n",
        "* Bias Model Estimates: In some cases, heteroscedasticity can introduce bias into the regression coefficients, leading to inaccurate and misleading results.\n",
        "\n",
        "**Addressing Heteroscedasticity**\n",
        "\n",
        "Several techniques can be used to address heteroscedasticity:\n",
        "\n",
        "* Weighted Least Squares (WLS): This method assigns weights to observations based on their variance, giving more weight to observations with lower variance.\n",
        "\n",
        "* Transformations: Transforming the dependent variable (e.g., using logarithmic or square root transformations) can sometimes stabilize the variance of the residuals.\n",
        "\n",
        "* Robust Regression Methods: These methods are less sensitive to the assumption of homoscedasticity and can provide more reliable estimates in the presence of heteroscedasticity.\n",
        "\n"
      ],
      "metadata": {
        "id": "g6LngxNnXoGh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q21.What does it mean if a Multiple Linear Regression model has a high R² but low adjusted R²?**"
      ],
      "metadata": {
        "id": "U1HagYZsS1Mq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans. High R-squared, Low Adjusted R-squared often indicates that your model might be overfitting the data. This means it's capturing noise and random fluctuations in the training data, rather than the true underlying relationships.\n",
        "\n",
        "**R-squared:**\n",
        "\n",
        "* Measures the proportion of variance in the dependent variable (the outcome you're trying to predict) that's explained by the independent variables (the predictors) in your model.\n",
        "\n",
        "* A high R-squared suggests that your model explains a large portion of the variation in the data.\n",
        "\n",
        "**Adjusted R-squared:**\n",
        "\n",
        "* A modified version of R-squared that accounts for the number of predictors in your model.\n",
        "\n",
        "* It penalizes models with a large number of predictors, even if they increase the R-squared slightly.\n",
        "\n",
        "* A low adjusted R-squared compared to the regular R-squared suggests that some of the predictors you've included might not be significantly improving the model's ability to generalize to new data.\n",
        "\n",
        "**Why it happens:**\n",
        "\n",
        "* Overfitting: When you include too many predictors in your model, it can start to \"memorize\" the noise and quirks of the specific training data. This leads to a high R-squared on the training data but poor performance on new, unseen data.\n",
        "\n",
        "* Irrelevant predictors: Some of the predictors in your model might not have a strong relationship with the dependent variable. Including these irrelevant predictors can inflate the R-squared but not improve the model's overall predictive power.\n",
        "\n",
        "**What to do:**\n",
        "\n",
        "* Feature selection: Carefully select the most relevant predictors for your model. Techniques like:\n",
        "\n",
        "* Forward selection: Gradually add predictors to the model, assessing their impact on the adjusted R-squared at each step.\n",
        "\n",
        "* Backward elimination: Start with all predictors and remove those that have the least impact on the adjusted R-squared.\n",
        "\n",
        "* Regularization methods: (e.g., Lasso, Ridge) These methods shrink the coefficients of less important predictors, effectively removing them from the model.\n",
        "\n",
        "* Increase sample size: If possible, collect more data to improve the model's ability to generalize.\n",
        "\n",
        "* Simplify the model: Consider using a simpler model with fewer predictors if it leads to a better balance between R-squared and adjusted R-squared.\n",
        "\n"
      ],
      "metadata": {
        "id": "7VfBBayfS7kX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q22.Why is it important to scale variables in Multiple Linear Regression?**"
      ],
      "metadata": {
        "id": "ysKFJXatV6rb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans. Scaling variables in multiple linear regression is crucial for several reasons:\n",
        "\n",
        "1. **Improved Gradient Descent Convergence:**\n",
        "\n",
        "* Gradient descent is an optimization algorithm commonly used to find the best-fitting regression line.\n",
        "\n",
        "* When features have vastly different scales, the gradient descent algorithm can take much longer to converge.\n",
        "\n",
        "* Scaling brings features to a similar range, allowing the algorithm to take more balanced steps and reach the optimal solution faster.\n",
        "\n",
        "2. **Enhanced Regularization Performance:**\n",
        "\n",
        "* Regularization techniques like Ridge and Lasso add penalties to the model's coefficients to prevent overfitting.\n",
        "\n",
        "* Features with larger scales can have a disproportionate impact on these penalties.\n",
        "\n",
        "* Scaling ensures that features contribute more equally to the regularization process, leading to better model performance.\n",
        "\n",
        "3. **Better Interpretability of Coefficients:**\n",
        "\n",
        "* In some cases, scaling can make the coefficients more interpretable.\n",
        "\n",
        "* For example, when using standardization (z-score scaling), coefficients represent the change in the dependent variable associated with a one-standard-deviation change in the predictor.\n",
        "\n",
        "4. **Improved Numerical Stability:**\n",
        "\n",
        "* Some algorithms can be sensitive to the scale of the data.\n",
        "\n",
        "* Scaling can help improve the numerical stability of the regression model and prevent potential issues during the training process\n",
        "\n",
        "**Common Scaling Methods:**\n",
        "\n",
        "* Standardization (Z-score scaling): Transforms features to have zero mean and unit variance.\n",
        "\n",
        "* Normalization (Min-Max scaling): Scales features to a specific range, typically between 0 and 1.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fYydoh1xWJcb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q23. What is polynomial regression?**"
      ],
      "metadata": {
        "id": "Hv-7Rix0ftTx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans.**Polynomial Regression: A Flexible Approach to Modeling Non-Linear Relationships**\n",
        "\n",
        "Polynomial regression is a statistical method used to model the relationship between a dependent variable and one or more independent variables when that relationship is not linear. It extends the concept of linear regression by introducing polynomial terms of the independent variables.\n",
        "\n",
        "**Key Points:**\n",
        "\n",
        "* Non-Linear Relationships: Unlike linear regression, which assumes a straight-line relationship, polynomial regression can capture curved patterns in the data.\n",
        "\n",
        "* Polynomial Terms: By adding higher-degree polynomial terms (quadratic, cubic, etc.) to the regression equation, the model can fit more complex curves.\n",
        "\n",
        "* Flexibility: Polynomial regression offers greater flexibility in modeling various shapes of relationships, including U-shaped, inverted U-shaped, and more complex curves.\n",
        "\n",
        "* Overfitting: A key consideration is the degree of the polynomial. Higher degrees can lead to overfitting, where the model fits the training data too closely and performs poorly on new data.\n",
        "\n",
        "**The Equation:**\n",
        "\n",
        "y = β₀ + β₁x + β₂x² + ... + βₙxⁿ + ε"
      ],
      "metadata": {
        "id": "XJPUfV40fzb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q24.- How does polynomial regression differ from linear regression?**"
      ],
      "metadata": {
        "id": "nKoQm_75iXOG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans. **Linear Regression**\n",
        "\n",
        "* Assumes a linear relationship: The relationship between the independent variable (x) and the dependent variable (y) is assumed to be a straight line.\n",
        "\n",
        "* Equation: y = a + bx.\n",
        "\n",
        "* Simple and interpretable: Easy to understand and visualize.\n",
        "\n",
        "* Limited flexibility: Cannot capture complex, non-linear patterns in the data.\n",
        "\n",
        "**Polynomial Regression**\n",
        "\n",
        "* Models non-linear relationships: Allows for curved relationships between variables by introducing polynomial terms.\n",
        "\n",
        "* Equation: y = a + b₁x + b₂x² + b₃x³ + ... + bₙxⁿ\n",
        "\n",
        "* Flexible: Can capture a wider range of patterns in the data, including curves and more complex shapes.\n",
        "\n",
        "* Potential for overfitting: Higher-degree polynomials can overfit the data, leading to poor performance on new, unseen data.\n",
        "\n",
        "**In essence:**\n",
        "\n",
        "* Linear regression is like drawing a straight line through the data points.\n",
        "\n",
        "* Polynomial regression is like bending and curving that line to better fit the data's shape.\n",
        "\n",
        "**When to Use Which:**\n",
        "\n",
        "* Linear Regression: If the relationship between variables appears to be linear.\n",
        "\n",
        "* Polynomial Regression: If the relationship is non-linear and you need a more flexible model to capture complex patterns\n"
      ],
      "metadata": {
        "id": "AqTr4t_8idA7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q25.- When is polynomial regression used?**"
      ],
      "metadata": {
        "id": "O7_W_2KBlsE-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans. Polynomial regression is used when the relationship between the independent variable (x) and the dependent variable (y) is not linear. It's particularly useful in situations where:\n",
        "\n",
        "* The data exhibits a curved pattern: If the scatter plot of the data points suggests a curve rather than a straight line, polynomial regression can better capture the underlying relationship.\n",
        "\n",
        "* Linear regression provides a poor fit: When linear regression fails to adequately model the data, resulting in high errors or a poor visual fit, polynomial regression can offer a more accurate representation.\n",
        "\n",
        "* The relationship is complex: In scenarios where the relationship between variables is not straightforward and involves multiple turning points or changes in direction, polynomial regression can provide a more flexible model.\n",
        "\n",
        "Here are some specific examples of when polynomial regression is used:\n",
        "\n",
        "* Finance:\n",
        "Modeling stock prices, interest rates, and other financial time series that often exhibit non-linear trends.\n",
        "\n",
        "* Engineering:\n",
        "Analyzing the relationship between variables in physical systems where non-linear behavior is common.\n",
        "\n",
        "* Social Sciences:\n",
        "Studying trends in social phenomena that may not follow linear patterns.\n",
        "\n",
        "* Machine Learning:\n",
        "As a foundational technique for more complex machine learning models, such as neural networks."
      ],
      "metadata": {
        "id": "eEtv4c2vmWaQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q26. What is the general equation for polynomial regression?**"
      ],
      "metadata": {
        "id": "mCB9QdGYo0I1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans. The general equation for polynomial regression of degree 'n' is:\n",
        "\n",
        "y = β₀ + β₁x + β₂x²+ ... + βₙxⁿ + ε\n",
        "\n",
        "Where:\n",
        "\n",
        "y is the dependent variable.\n",
        "x is the independent variable.\n",
        "β₀, β₁, ..., βₙ are the coefficients of the polynomial terms.\n",
        "ε is the error term."
      ],
      "metadata": {
        "id": "7QorhgWUo79-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q27.Can polynomial regression be applied to multiple variables?**"
      ],
      "metadata": {
        "id": "6rJS0t0MqsUG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans. Yes, polynomial regression can be applied to multiple variables. This is often referred to as multivariate polynomial regression.\n",
        "\n",
        "Here's how it works:\n",
        "\n",
        "* Multiple Independent Variables: Instead of just one independent variable (x), you have multiple independent variables (x1, x2, x3, ...).\n",
        "\n",
        "* Polynomial Terms: You include not only the linear terms of these variables but also their higher-order terms (squared, cubed, etc.) and interaction terms between them.\n",
        "\n",
        "y = β₀ + β₁x₁ + β₂x₂ + β₃x₁² + β₄x₂² + β₅x₁x₂\n",
        "\n",
        "β₀: Intercept\n",
        "β₁: Coefficient for x₁\n",
        "β₂: Coefficient for x₂\n",
        "β₃: Coefficient for the squared term of x₁\n",
        "β₄: Coefficient for the squared term of x₂\n",
        "β₅: Coefficient for the interaction term between x₁ and x₂\n",
        "ε: Error term"
      ],
      "metadata": {
        "id": "N7rXcEDqqyY8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q28.What are the limitations of polynomial regression?**"
      ],
      "metadata": {
        "id": "rz2lGSPXtDzO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans. **1. Overfitting:**\n",
        "\n",
        "* The Curse of Dimensionality: As the degree of the polynomial increases, the model's flexibility grows significantly. This can lead to overfitting, where the model captures noise and random fluctuations in the training data instead of the underlying trend.\n",
        "\n",
        "* Poor Generalization: Overfitted models perform poorly on new, unseen data, as they have essentially memorized the training data.\n",
        "\n",
        "**2. Sensitivity to Outliers:**\n",
        "\n",
        "* Outliers can have a disproportionate impact on the fitting of the polynomial curve, especially with higher-degree polynomials. This can significantly distort the model and lead to inaccurate predictions.\n",
        "\n",
        "\n",
        "**3. Difficulty in Interpretation:**\n",
        "\n",
        "* Higher-degree polynomials can be complex and difficult to interpret. Understanding the relationship between the independent and dependent variables becomes challenging as the number of terms and their interactions increase.\n",
        "\n",
        "**4. Computational Complexity:**\n",
        "\n",
        "* Fitting high-degree polynomials can be computationally expensive, especially with large datasets. The number of calculations required increases significantly with the degree of the polynomial.\n",
        "\n",
        "**5. Choosing the Degree:**\n",
        "\n",
        "* Determining the optimal degree of the polynomial is crucial. A low degree may underfit the data, while a high degree may overfit. Selecting the appropriate degree often requires trial and error and techniques like cross-validation, adding to the complexity of the modeling process.\n",
        "\n",
        "**6. Extrapolation:**\n",
        "\n",
        "* Polynomial regression models may not accurately predict values outside the range of the observed data, especially with high-degree polynomials. Extrapolation can lead to unreliable and potentially misleading results."
      ],
      "metadata": {
        "id": "xF870msXtJ1I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q29. What methods can be used to evaluate model fit when selecting the degree of a polynomial?**"
      ],
      "metadata": {
        "id": "sgss23eyu5Z3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans. When selecting the degree of a polynomial for a regression model, it's important to evaluate the model fit to avoid underfitting or overfitting. Here are some common methods to evaluate model fit:\n",
        "\n",
        "### 1. **Visual Inspection**\n",
        "   - **Plot the Data**: Plot the observed data points and overlay the polynomial regression curve. This helps visually assess how well the polynomial fits the data.\n",
        "   - **Residual Plots**: Plot the residuals (differences between observed and predicted values) against the independent variable or the predicted values. A good fit will show residuals randomly scattered around zero without any clear pattern.\n",
        "\n",
        "### 2. **R-squared (Coefficient of Determination)**\n",
        "   - **R-squared** measures the proportion of variance in the dependent variable that is explained by the independent variables. A higher R-squared indicates a better fit.\n",
        "   - However, R-squared always increases with higher polynomial degrees, so it should not be used alone.\n",
        "\n",
        "### 3. **Adjusted R-squared**\n",
        "   - **Adjusted R-squared** adjusts for the number of predictors in the model. It penalizes the addition of unnecessary terms, making it more suitable for comparing models with different polynomial degrees.\n",
        "\n",
        "### 4. **Cross-Validation**\n",
        "   - **k-Fold Cross-Validation**: Split the data into \\(k\\) subsets, train the model on \\(k-1\\) subsets, and validate it on the remaining subset. Repeat this process \\(k\\) times and average the performance metrics (e.g., mean squared error, MSE) to evaluate the model.\n",
        "   - Cross-validation helps assess how well the model generalizes to unseen data, reducing the risk of overfitting.\n",
        "\n",
        "### 5. **Information Criteria**\n",
        "   - **Akaike Information Criterion (AIC)**: Balances model fit and complexity. Lower AIC values indicate a better trade-off between goodness-of-fit and simplicity.\n",
        "   - **Bayesian Information Criterion (BIC)**: Similar to AIC but imposes a stronger penalty for additional parameters. Lower BIC values are preferred.\n",
        "\n",
        "### 6. **Mean Squared Error (MSE) or Root Mean Squared Error (RMSE)**\n",
        "   - **MSE** measures the average squared difference between observed and predicted values. Lower MSE indicates a better fit.\n",
        "   - **RMSE** is the square root of MSE and is in the same units as the dependent variable, making it easier to interpret.\n",
        "\n",
        "### 7. **Training vs. Test Error**\n",
        "   - Compare the model's performance on the training data versus a separate test dataset. If the training error is much lower than the test error, the model may be overfitting.\n",
        "\n",
        "### 8. **Likelihood Ratio Test**\n",
        "   - For nested models (e.g., comparing a quadratic model to a linear model), use a likelihood ratio test to determine if the additional terms significantly improve the fit.\n",
        "\n",
        "### 9. **Regularization Techniques**\n",
        "   - Use techniques like **Ridge Regression** or **Lasso Regression** to penalize higher-degree terms and prevent overfitting.\n",
        "\n",
        "### 10. **Domain Knowledge**\n",
        "   - Consider the context of the problem and domain knowledge. Sometimes, a simpler model with a lower degree may be preferred even if it has a slightly worse fit, as it is more interpretable and generalizable.\n"
      ],
      "metadata": {
        "id": "Q-_kRL5vu_sL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q30. Why is visualization important in polynomial regression?**"
      ],
      "metadata": {
        "id": "ECPQTB67wqDj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans. Visualization is a critical tool in polynomial regression for several reasons:\n",
        "\n",
        "### 1. **Assessing Model Fit**\n",
        "   - **Observing the Curve**: Plotting the polynomial regression curve alongside the actual data points allows you to visually assess how well the model captures the underlying trend. This helps identify whether the model is underfitting (too simple) or overfitting (too complex).\n",
        "   - **Residual Analysis**: Plotting residuals (the differences between observed and predicted values) can reveal patterns that indicate poor fit, such as systematic deviations or heteroscedasticity (non-constant variance).\n",
        "\n",
        "### 2. **Detecting Overfitting or Underfitting**\n",
        "   - **Overfitting**: A high-degree polynomial may fit the training data very closely but produce erratic predictions outside the observed range. Visualization helps spot this by showing unrealistic oscillations in the curve.\n",
        "   - **Underfitting**: A low-degree polynomial may fail to capture important patterns in the data, which is evident when the curve is too smooth and misses key trends.\n",
        "\n",
        "### 3. **Understanding the Data**\n",
        "   - **Identifying Nonlinear Relationships**: Visualization helps reveal whether the relationship between the independent and dependent variables is linear or nonlinear, guiding the choice of polynomial degree.\n",
        "   - **Spotting Outliers or Anomalies**: Scatterplots can highlight outliers or unusual data points that might disproportionately influence the regression model.\n",
        "\n",
        "### 4. **Comparing Models**\n",
        "   - **Side-by-Side Comparisons**: Visualizing multiple polynomial fits (e.g., linear, quadratic, cubic) on the same plot allows for easy comparison of their performance and helps select the most appropriate degree.\n",
        "   - **Trade-offs Between Complexity and Fit**: Visualization makes it easier to balance model complexity (degree of the polynomial) with the quality of fit.\n",
        "\n",
        "### 5. **Communicating Results**\n",
        "   - **Interpretability**: Visualizations make it easier to explain the model's behavior and predictions to stakeholders who may not be familiar with statistical metrics.\n",
        "   - **Intuitive Insights**: A well-constructed plot can convey insights about the data and model that might be less obvious from numerical metrics alone.\n",
        "\n",
        "### 6. **Diagnosing Issues**\n",
        "   - **Heteroscedasticity**: Residual plots can reveal whether the variance of errors changes across the range of the independent variable, which violates regression assumptions.\n",
        "   - **Multicollinearity**: In multiple polynomial regression, visualization can help detect multicollinearity issues by showing relationships between predictors.\n",
        "\n",
        "### 7. **Guiding Model Selection**\n",
        "   - **Choosing the Right Degree**: Visualization helps determine the appropriate polynomial degree by showing how adding higher-order terms affects the curve's flexibility and fit.\n",
        "   - **Avoiding Extrapolation Risks**: Visualization highlights where the polynomial model may behave unreliably outside the range of the observed data.\n",
        "\n",
        "### Practical Example\n",
        "Suppose you are fitting a polynomial regression to data that appears to follow a curved trend. By plotting:\n",
        "- The data points,\n",
        "- The fitted polynomial curve, and\n",
        "- The residuals,\n",
        "you can quickly see if the curve aligns well with the data, whether the residuals are randomly distributed, and whether higher-degree terms are necessary or excessive.\n",
        "\n",
        "### Summary\n",
        "Visualization is indispensable in polynomial regression because it provides intuitive, immediate insights into the model's performance, helps diagnose potential issues, and aids in selecting the optimal degree of the polynomial. It complements numerical metrics and enhances the interpretability and reliability of the regression analysis."
      ],
      "metadata": {
        "id": "OgSVj4nixNMw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q31. How is polynomial regression implemented in Python?**"
      ],
      "metadata": {
        "id": "jOnWSsRzyyQP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "np.random.seed(42)\n",
        "X = np.random.rand(100, 1) * 10\n",
        "y = 2 * X**2 + 3 * X + 4 + np.random.randn(100, 1) * 10\n",
        "\n",
        "degree = 2\n",
        "poly_features = PolynomialFeatures(degree=degree)\n",
        "X_poly = poly_features.fit_transform(X)\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X_poly, y)\n",
        "y_pred = model.predict(X_poly)\n",
        "\n",
        "mse = mean_squared_error(y, y_pred)\n",
        "r2 = r2_score(y, y_pred)\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"R-squared: {r2}\")\n",
        "\n",
        "sorted_indices = np.argsort(X[:, 0])\n",
        "X_sorted = X[sorted_indices]\n",
        "y_pred_sorted = y_pred[sorted_indices]\n",
        "\n",
        "plt.scatter(X, y, color='blue', label='Data points')\n",
        "plt.plot(X_sorted, y_pred_sorted, color='red', label='Polynomial fit')\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('y')\n",
        "plt.title(f'Polynomial Regression (Degree {degree})')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "HV-i0hHuBeeC",
        "outputId": "a3f48464-6a41-48a4-8fd4-571cfb02b97b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 77.71936663502369\n",
            "R-squared: 0.9830777258012564\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}